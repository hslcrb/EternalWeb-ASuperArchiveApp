
# EternalWeb Core Engine
# Orchestrates ArchiveBox, SingleFile, and ArchiveWeb.page

import os
import sys
import subprocess
import json
from datetime import datetime
from pathlib import Path
from ..config import get_config

# í†µí•© ì„¤ì • ë¡œë“œ
config = get_config()

# Paths adjustment for new structure
# This file is in src/eternalweb/engine/engine.py
# Components are in src/eternalweb/components/

CORE_DIR = Path(__file__).parent
COMPONENTS_DIR = CORE_DIR.parent / "components"
ARCHIVEBOX_DIR = CORE_DIR / "archivebox" # Moved here earlier

# Legacy Support: Add core dir to sys.path so 'import archivebox' works
sys.path.append(str(CORE_DIR))

def init_engine():
    """ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ ì—”ì§„ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    print(f"EternalWeb ì—”ì§„ ì½”ì–´ ì´ˆê¸°í™” ì¤‘... (ì €ì¥ê²½ë¡œ: {config['storage_path']})")
    print(f"êµ¬ì„± ìš”ì†Œ ê²½ë¡œ: {COMPONENTS_DIR}")
    
    # Check Components
    if (COMPONENTS_DIR / "singlefile").exists():
        print("âœ” êµ¬ì„± ìš”ì†Œ ë¡œë“œë¨: SingleFile (ê³ í•´ìƒë„)")
    else:
        print("âœ˜ êµ¬ì„± ìš”ì†Œ ëˆ„ë½: SingleFile")

    if (COMPONENTS_DIR / "webpage").exists():
        print("âœ” êµ¬ì„± ìš”ì†Œ ë¡œë“œë¨: ArchiveWeb.page (ëŒ€í™”í˜• ì•„ì¹´ì´ë¸Œ)")
    else:
        print("âœ˜ êµ¬ì„± ìš”ì†Œ ëˆ„ë½: ArchiveWeb.page")

    # Verify ArchiveBox
    try:
        # Since we moved archivebox to src/eternalweb/engine/archivebox,
        # we need to make sure it's importable.
        # It's a subdirectory here, so it should be fine if __init__.py exists.
        from . import archivebox
        print(f"âœ” ì½”ì–´ ë¡œë“œë¨: ArchiveBox ë ˆê±°ì‹œ ì—”ì§„")
    except ImportError as e:
        print(f"âš  ArchiveBox ì„í¬íŠ¸ ë¬¸ì œ ë°œìƒ: {e}")

class Archiver:
    def __init__(self, log_fn=None):
        self.active_jobs = []
        self.log_fn = log_fn if log_fn else print

    def archive_url(self, url, options=None):
        if options is None:
            options = ["WACZ", "SingleFile"]

        storage_path = Path(config['storage_path'])
        storage_path.mkdir(parents=True, exist_ok=True)
        
        # ì•„ì¹´ì´ë¸Œ ê²°ê³¼ ë°ì´í„° (Library ì—°ë™ìš©)
        archive_id = Path(url.replace("://", "_").replace("/", "_")).name[:50]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        job_dir = storage_path / f"{timestamp}_{archive_id}"
        job_dir.mkdir(parents=True, exist_ok=True)
 
        return self.run_archiving(url, options, job_dir)

    def run_archiving(self, url, options, job_dir):
        self.log(f"âš¡ [ì´í„°ë„ì›¹] ì—”ì§„ ê°€ë™: {url}")
        self.log(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {job_dir}")
        
        # timestampëŠ” í´ë”ëª…ì—ì„œ ì§ì ‘ íŒŒì‹± (YYYYMMDD_HHMMSS í˜•ì‹ ìœ ì§€)
        ts_part = job_dir.name.split('_')[0] + "_" + job_dir.name.split('_')[1]
        results = {"url": url, "timestamp": ts_part, "path": str(job_dir), "formats": []}
        
        # í†µí•© ì•„ì¹´ì´ë¹™ ì—”ì§„ (Playwright ê¸°ë°˜)
        # Level 1 (HTML)ê³¼ Level 2 (WACZ)ë¥¼ í•œ ë²ˆì˜ ë¸Œë¼ìš°ì € ì„¸ì…˜ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        wacz_path = job_dir / "interactive.wacz"
        html_path = job_dir / "snapshot.html"
        
        needed_wacz = "WACZ" in options
        needed_html = "SingleFile" in options or "HTML" in options
        
        if needed_wacz or needed_html:
            self.log(f"ğŸš€ [í†µí•© ì—”ì§„] Playwright ê³ ì„±ëŠ¥ ìº¡ì²˜ ì‹œì‘...")
            capture_script = CORE_DIR / "wacz_capture.py"
            
            # íŒŒë¼ë¯¸í„° êµ¬ì„±
            cmd = [sys.executable, str(capture_script), url, str(wacz_path)]
            if needed_html:
                cmd.append(str(html_path))
            
            res = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if html_path.exists():
                self.log("âœ” [Level 1] HTML ìŠ¤ëƒ…ìƒ· ì €ì¥ ì™„ë£Œ")
                results["formats"].append("HTML")
            
            if wacz_path.exists():
                self.log("âœ” [Level 2] WACZ ì¸í„°ë™í‹°ë¸Œ ì•„ì¹´ì´ë¸Œ ì™„ë£Œ")
                results["formats"].append("WACZ")
            else:
                self.log(f"âš  Playwright ìº¡ì²˜ ì‹¤íŒ¨ (ì½”ë“œ: {res.returncode})")
                if res.stderr: self.log(f"ìƒì„¸ ë¡œê·¸:\n{res.stderr[-500:]}")
                
                # Fallback: Browsertrix Crawler (WACZìš©)
                if needed_wacz:
                    self.log("â„¹ ëŒ€ì²´ ì—”ì§„ (Browsertrix) ì‹œë„ ì¤‘...")
                    save_dir = job_dir / "wacz_tmp"
                    save_dir.mkdir(exist_ok=True)
                    # npx @webrecorder/browsertrix-crawler ê°€ 404ë‚˜ë©´ browsertrix-crawler ë„ ì‹œë„
                    bt_cmd = ["npx", "-y", "@webrecorder/browsertrix-crawler", "crawl", 
                           "--url", url, "--generateWACZ", "--output", str(save_dir), "--workers", "1"]
                    
                    alt_res = subprocess.run(bt_cmd, capture_output=True, text=True, check=False)
                    wacz_files = list(save_dir.glob("**/*.wacz"))
                    if wacz_files:
                        import shutil
                        shutil.move(str(wacz_files[0]), str(wacz_path))
                        self.log("âœ” [Level 2] WACZ ì™„ë£Œ (Browsertrix)")
                        results["formats"].append("WACZ")
                
                # Fallback: SingleFile (HTML ì „ìš©)
                if needed_html and not html_path.exists():
                    self.run_singlefile(url, html_path)
                    if html_path.exists(): results["formats"].append("HTML")

        # 3. ArchiveBox (Level 3)
        if any(opt in options for opt in ["WARC", "Media", "PDF", "Screenshot"]):
            self.run_archivebox(url, options, job_dir)
            results["formats"].append("ArchiveBox")
        
        self.save_to_library(results)
        return results

    def log(self, message):
        """ì»¤ë§¨ë“œ ë° GUI ë¡œê·¸ ë™ì‹œ ì¶œë ¥"""
        t = datetime.now().strftime('%H:%M:%S')
        msg = f"[{t}] {message}"
        print(msg)
        if self.log_fn:
            self.log_fn(message)

    def run_singlefile(self, url, out_path):
        self.log(f"ğŸ“¸ [Level 1] ìŠ¤ëƒ…ìƒ· ì¶”ì¶œ ì¤‘ (single-file-cli)...")
        try:
            # single-file-cli ì˜µì…˜ ìµœì í™”: ë¸Œë¼ìš°ì € ì¸ì ê°•í™” ë° ëŒ€ê¸° ì‹œê°„ ì¡°ì •
            cmd = [
                "npx", "-y", "single-file-cli", 
                url, str(out_path), 
                "--browser-args", '["--no-sandbox", "--disable-setuid-sandbox", "--ignore-certificate-errors", "--disable-web-security", "--disable-features=IsolateOrigins,site-per-process"]',
                "--user-agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "--load-deferred-images-dispatch-scroll-event", "true",
                "--browser-wait-until", "networkIdle",
                "--browser-load-max-time", "120000",
                "--browser-wait-delay", "3000"
            ]
            
            # ì‹¤í–‰ ì‹œ í™˜ê²½ ë³€ìˆ˜ì—ì„œ NODE_OPTIONS ë“±ì„ ì œê±°í•˜ì—¬ ìˆœìˆ˜ npx ì‹¤í–‰ ì‹œë„
            env = os.environ.copy()
            # npm ì¸ì¦ ê²½ê³  ë°©ì§€
            env["NPM_CONFIG_REGISTRY"] = "https://registry.npmjs.org/"
            
            result = subprocess.run(cmd, env=env, capture_output=True, text=True, check=False)
            
            if out_path.exists() and out_path.stat().st_size > 500:
                self.log("âœ” Level 1 HTML ìŠ¤ëƒ…ìƒ· ì €ì¥ ì™„ë£Œ")
            else:
                self.log(f"âŒ Level 1 ì‹¤íŒ¨ (ì½”ë“œ: {result.returncode})")
                if result.stderr: self.log(f"ìƒì„¸ ì—ëŸ¬:\n{result.stderr[-500:]}")
                if result.stdout: self.log(f"í‘œì¤€ ì¶œë ¥:\n{result.stdout[-200:]}")
        except Exception as e:
            self.log(f"âŒ SingleFile ì˜ˆì™¸ ë°œìƒ: {e}")

    def run_archivebox(self, url, options, job_dir):
        self.log(f"ğŸ“¦ [Level 3] ë‚´ì¥ ArchiveBox ì—”ì§„ ê°€ë™ ì¤‘...")
        # 0.8.x ë²„ì „ì—ì„œëŠ” --extract ëŒ€ì‹  --pluginsë¥¼ ì‚¬ìš©í•¨
        plugins = []
        if "WARC" in options: plugins.append("wget")
        if "PDF" in options: plugins.append("pdf")
        if "Media" in options: plugins.append("media")
        if "Screenshot" in options: plugins.append("screenshot")
        
        try:
            engine_root = str(CORE_DIR.resolve())
            env = os.environ.copy()
            env["PYTHONPATH"] = f"{engine_root}{os.pathsep}{env.get('PYTHONPATH', '')}"
            
            # 1. ì´ˆê¸°í™”
            self.log("â„¹ ArchiveBox ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
            init_res = subprocess.run([sys.executable, "-m", "archivebox", "init", "--force"], 
                                      cwd=job_dir, env=env, capture_output=True, text=True, check=False)
            
            if not (job_dir / "index.sqlite3").exists():
                self.log(f"âš  Level 3 ì´ˆê¸°í™” ì‹¤íŒ¨. ë¡œê·¸:\n{init_res.stderr[-300:]}")
                return
            
            # 2. ì¶”ê°€ ë° ì¶”ì¶œ
            self.log(f"â„¹ ArchiveBox í”ŒëŸ¬ê·¸ì¸ ì‹¤í–‰: {', '.join(plugins) if plugins else 'all'}")
            cmd = [sys.executable, "-m", "archivebox", "add", url]
            if plugins:
                cmd.append(f"--plugins={','.join(plugins)}")
            
            result = subprocess.run(cmd, cwd=job_dir, env=env, capture_output=True, text=True, check=False)
            if result.returncode != 0:
                self.log(f"âŒ Level 3 ì‹¤íŒ¨. ë¡œê·¸:\n{result.stderr[-400:]}")
            else:
                self.log("âœ” Level 3 ì‹¬ì¸µ ì•„ì¹´ì´ë¸Œ ì™„ë£Œ")
        except Exception as e:
            self.log(f"âŒ ArchiveBox ì˜ˆì™¸ ë°œìƒ: {e}")

    def save_to_library(self, data):
        """ì•„ì¹´ì´ë¸Œ ê²°ê³¼ë¥¼ ì¤‘ì•™ ì¸ë±ìŠ¤ íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤."""
        index_file = Path(config['storage_path']) / "index.json"
        library = []
        if index_file.exists() and index_file.stat().st_size > 0:
            try:
                with open(index_file, "r", encoding="utf-8") as f:
                    library = json.load(f)
            except json.JSONDecodeError:
                self.log_fn("âš  ë¼ì´ë¸ŒëŸ¬ë¦¬ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                library = []
        
        library.append(data)
        with open(index_file, "w", encoding="utf-8") as f:
            json.dump(library, f, indent=4, ensure_ascii=False)
        self.log_fn(f"ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥ ì™„ë£Œ: {data['url']}")

