
# EternalWeb Core Engine
# Orchestrates ArchiveBox, SingleFile, and ArchiveWeb.page

import os
import sys
import subprocess
import json
from pathlib import Path
from ..config import get_config

# í†µí•© ì„¤ì • ë¡œë“œ
config = get_config()

# Paths adjustment for new structure
# This file is in src/eternalweb/engine/engine.py
# Components are in src/eternalweb/components/

CORE_DIR = Path(__file__).parent
COMPONENTS_DIR = CORE_DIR.parent / "components"
ARCHIVEBOX_DIR = CORE_DIR / "archivebox" # Moved here earlier

# Legacy Support: Add core dir to sys.path so 'import archivebox' works
sys.path.append(str(CORE_DIR))

def init_engine():
    """ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ ì—”ì§„ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    print(f"EternalWeb ì—”ì§„ ì½”ì–´ ì´ˆê¸°í™” ì¤‘... (ì €ì¥ê²½ë¡œ: {config['storage_path']})")
    print(f"êµ¬ì„± ìš”ì†Œ ê²½ë¡œ: {COMPONENTS_DIR}")
    
    # Check Components
    if (COMPONENTS_DIR / "singlefile").exists():
        print("âœ” êµ¬ì„± ìš”ì†Œ ë¡œë“œë¨: SingleFile (ê³ í•´ìƒë„)")
    else:
        print("âœ˜ êµ¬ì„± ìš”ì†Œ ëˆ„ë½: SingleFile")

    if (COMPONENTS_DIR / "webpage").exists():
        print("âœ” êµ¬ì„± ìš”ì†Œ ë¡œë“œë¨: ArchiveWeb.page (ëŒ€í™”í˜• ì•„ì¹´ì´ë¸Œ)")
    else:
        print("âœ˜ êµ¬ì„± ìš”ì†Œ ëˆ„ë½: ArchiveWeb.page")

    # Verify ArchiveBox
    try:
        # Since we moved archivebox to src/eternalweb/engine/archivebox,
        # we need to make sure it's importable.
        # It's a subdirectory here, so it should be fine if __init__.py exists.
        from . import archivebox
        print(f"âœ” ì½”ì–´ ë¡œë“œë¨: ArchiveBox ë ˆê±°ì‹œ ì—”ì§„")
    except ImportError as e:
        print(f"âš  ArchiveBox ì„í¬íŠ¸ ë¬¸ì œ ë°œìƒ: {e}")

class Archiver:
    def __init__(self, log_fn=None):
        self.active_jobs = []
        self.log_fn = log_fn if log_fn else print

    def archive_url(self, url, options=None):
        if options is None:
            options = ["WACZ", "SingleFile"]

        storage_path = Path(config['storage_path'])
        storage_path.mkdir(parents=True, exist_ok=True)
        
        # ì•„ì¹´ì´ë¸Œ ê²°ê³¼ ë°ì´í„° (Library ì—°ë™ìš©)
        archive_id = Path(url.replace("://", "_").replace("/", "_")).name[:50]
        timestamp = Path(os.popen("date +%Y%m%d_%H%M%S").read().strip()).name
        job_dir = storage_path / f"{timestamp}_{archive_id}"
        job_dir.mkdir(parents=True, exist_ok=True)
 
        self.log_fn(f"âš¡ [ì´í„°ë„ì›¹] ì—”ì§„ ê°€ë™: {url}")
        self.log_fn(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {job_dir}")
        
        results = {"url": url, "timestamp": timestamp, "path": str(job_dir), "formats": []}

        # 1. Level 1: SingleFile
        if "SingleFile" in options:
            out_file = job_dir / "snapshot.html"
            self.run_singlefile(url, out_file)
            results["formats"].append("HTML")

        # 2. Level 2: ArchiveWeb.page (WACZ)
        if "WACZ" in options:
            out_wacz = job_dir / "interactive.wacz"
            self.run_interactive_archiver(url, out_wacz)
            results["formats"].append("WACZ")

        # 3. Level 3: ArchiveBox
        if any(opt in options for opt in ["WARC", "Media", "PDF", "Screenshot"]):
            self.run_archivebox(url, options, job_dir)
            results["formats"].append("ArchiveBox")

        self.save_to_library(results)
        return results

    def run_interactive_archiver(self, url, out_path):
        self.log_fn(f"ğŸš€ [Level 2] ê³  fidelity ì•„ì¹´ì´ë¹™ ì‹œì‘ (Playwright + WACZ)...")
        try:
            # src/eternalweb/engine/wacz_capture.py ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ í™•ì¸
            capture_script = CORE_DIR / "wacz_capture.py"
            
            # Playwright ë¸Œë¼ìš°ì €ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ìë™ ì„¤ì¹˜ ì‹œë„ ìƒëµí•˜ê³  ì‹¤í–‰)
            # .venv/bin/python ì„ ì‚¬ìš©í•˜ì—¬ ë™ì¼í•œ í™˜ê²½ì—ì„œ ì‹¤í–‰
            self.log_fn("â„¹ Playwright ì—”ì§„ ë° ë¸Œë¼ìš°ì € ì„¸ì…˜ ê°€ë™...")
            
            result = subprocess.run([sys.executable, str(capture_script), url, str(out_path)], 
                                    capture_output=True, text=True, check=False)
            
            if out_path.exists() and out_path.stat().st_size > 1000:
                self.log_fn("âœ” Level 2 WACZ ì•„ì¹´ì´ë¸Œ ì™„ë£Œ (ê³ í™”ì§ˆ)")
            else:
                self.log_fn("â„¹ Browsertrix Crawler ëŒ€ì²´ ì—”ì§„ ì‹œë„ ì¤‘...")
                # Fallback to browsertrix-crawler if Playwright fails
                save_dir = out_path.parent / "wacz_tmp"
                save_dir.mkdir(exist_ok=True)
                cmd = ["npx", "-y", "@webrecorder/browsertrix-crawler", "crawl", 
                       "--url", url, "--generateWACZ", "--output", str(save_dir), "--workers", "1"]
                
                alt_result = subprocess.run(cmd, capture_output=True, text=True, check=False)
                wacz_files = list(save_dir.glob("**/*.wacz"))
                if wacz_files:
                    import shutil
                    shutil.move(str(wacz_files[0]), str(out_path))
                    self.log_fn("âœ” Level 2 WACZ ì•„ì¹´ì´ë¸Œ ì™„ë£Œ (Browsertrix)")
                else:
                    self.log_fn(f"âŒ Level 2 ì‹¤íŒ¨: {result.stderr[-200:]}")
        except Exception as e:
            self.log_fn(f"âŒ Level 2 ì˜ˆì™¸: {e}")

    def run_singlefile(self, url, out_path):
        self.log_fn(f"ğŸ“¸ [Level 1] ìŠ¤ëƒ…ìƒ· ì¶”ì¶œ ì¤‘ (single-file-cli)...")
        try:
            # single-file-cli ì‹¤í–‰
            # Warning ë©”ì‹œì§€(stdout/stderr)ì— ìƒê´€ì—†ì´ íŒŒì¼ì´ ìƒì„±ë˜ë©´ ì„±ê³µìœ¼ë¡œ íŒë‹¨
            result = subprocess.run(["npx", "-y", "single-file-cli", url, str(out_path), "--browser-args", '["--no-sandbox"]'], 
                                    capture_output=True, text=True, check=False)
            
            if out_path.exists() and out_path.stat().st_size > 1000:
                self.log_fn("âœ” Level 1 HTML ìŠ¤ëƒ…ìƒ· ì €ì¥ ì™„ë£Œ")
            else:
                # ì—ëŸ¬ ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¸¸ë©´ ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ ì¶œë ¥
                err = result.stderr[-200:] if result.stderr else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                self.log_fn(f"âŒ Level 1 ì‹¤íŒ¨: {err}")
        except Exception as e:
            self.log_fn(f"âŒ SingleFile ì˜ˆì™¸: {e}")

    def run_archivebox(self, url, options, job_dir):
        self.log_fn(f"ğŸ“¦ [Level 3] ë‚´ì¥ ArchiveBox ì—”ì§„ ê°€ë™ ì¤‘...")
        extractors = []
        if "WARC" in options: extractors.append("wget")
        if "PDF" in options: extractors.append("pdf")
        if "Media" in options: extractors.append("media")
        if "Screenshot" in options: extractors.append("screenshot")
        
        try:
            # CORE_DIRëŠ” src/eternalweb/engine ì„.
            # ì´ ë””ë ‰í† ë¦¬ê°€ PYTHONPATHì— ìˆì–´ì•¼ 'import archivebox'ê°€ ê°€ëŠ¥í•¨.
            engine_root = str(CORE_DIR.resolve())
            
            env = os.environ.copy()
            env["PYTHONPATH"] = f"{engine_root}{os.pathsep}{env.get('PYTHONPATH', '')}"
            
            # 1. ì´ˆê¸°í™”
            init_res = subprocess.run([sys.executable, "-m", "archivebox", "init", "--force"], 
                                      cwd=job_dir, env=env, capture_output=True, text=True, check=False)
            
            if not (job_dir / "index.sqlite3").exists():
                self.log_fn(f"âš  Level 3 ì´ˆê¸°í™” ì‹¤íŒ¨: {init_res.stderr[-200:]}")
                return
            
            # 2. ì¶”ê°€ ë° ì¶”ì¶œ
            cmd = [sys.executable, "-m", "archivebox", "add", url]
            if extractors:
                cmd.append(f"--extract={','.join(extractors)}")
            
            result = subprocess.run(cmd, cwd=job_dir, env=env, capture_output=True, text=True, check=False)
            if result.returncode != 0:
                self.log_fn(f"âŒ Level 3 ì‹¤íŒ¨: {result.stderr[-200:]}")
            else:
                self.log_fn("âœ” Level 3 ì‹¬ì¸µ ì•„ì¹´ì´ë¸Œ ì™„ë£Œ")
        except Exception as e:
            self.log_fn(f"âŒ ArchiveBox ì˜ˆì™¸: {e}")

    def save_to_library(self, data):
        """ì•„ì¹´ì´ë¸Œ ê²°ê³¼ë¥¼ ì¤‘ì•™ ì¸ë±ìŠ¤ íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤."""
        index_file = Path(config['storage_path']) / "index.json"
        library = []
        if index_file.exists() and index_file.stat().st_size > 0:
            try:
                with open(index_file, "r", encoding="utf-8") as f:
                    library = json.load(f)
            except json.JSONDecodeError:
                self.log_fn("âš  ë¼ì´ë¸ŒëŸ¬ë¦¬ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                library = []
        
        library.append(data)
        with open(index_file, "w", encoding="utf-8") as f:
            json.dump(library, f, indent=4, ensure_ascii=False)
        self.log_fn(f"ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥ ì™„ë£Œ: {data['url']}")

